{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9r4ROd17pfG"
   },
   "source": [
    "# Scraping Top Rated Movies from IMDB\n",
    "Python script to scrape the top 100 movies for every year from 2011 to 2021 based on the number of votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz27r3ICa4Pv"
   },
   "source": [
    "### Steps to follow:\n",
    "- I am going to scrape https://www.imdb.com\n",
    "- I will get a list of top 100 movies in an year according to the number votes, for each movie I will fetch the movie_url, duration and number of votes.\n",
    "- For each movie I will fetch some more important details\n",
    "- For each year data I will save the CSV file and one file for all years of data inside a *Results* folder.\n",
    "- For each movie the CSV file contains the data in the below format:\n",
    "\n",
    "```\n",
    "title,tagline,no_of_directors,directors,no_of_writers,writers,lead_stars,released_year,oscar_wins,genres,award_nominations,award_wins,rating,votes,metascore,duration,county_of_origins,production_companies,url\n",
    "\n",
    "Dune,\"Beyond fear, destiny awaits.\",1,Denis Villeneuve,3,\"Jon Spaihts(screenplay by),Denis Villeneuve(screenplay by),Eric Roth(screenplay by)\",\"Timoth√©e Chalamet,Rebecca Ferguson,Zendaya\",2021,0,\"Action,Adventure,Drama,Sci-Fi\",245,88,8.1,471926,74,155,\"United States,Canada\",\"Warner Bros.,Legendary Entertainment,Villeneuve Films\",https://www.imdb.com/title/tt1160419/\n",
    "\n",
    "Spider-Man: No Way Home,The Multiverse Unleashed.,1,Jon Watts,3,\"Chris McKenna,Erik Sommers,Stan Lee(based on the Marvel comic book by)\",\"Tom Holland,Zendaya,Benedict Cumberbatch\",2021,0,\"Action,Adventure,Fantasy,Sci-Fi\",31,4,8.7,439898,71,148,United States,\"Columbia Pictures,Pascal Pictures,Marvel Studios\",https://www.imdb.com/title/tt10872600/\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXA1LKzg7tFq"
   },
   "source": [
    "### Fields to scrape\n",
    "- Title\n",
    "- Tagline\n",
    "- No Of Directors\n",
    "- Directors\n",
    "- No Of Writers\n",
    "- Writers\n",
    "- Lead Stars\n",
    "- Released Year\n",
    "- Oscar Wins\n",
    "- Genres\n",
    "- Award Nominations\n",
    "- Award Wins\n",
    "- Rating\n",
    "- Votes\n",
    "- Metascore\n",
    "- Duration\n",
    "- County Of Origins\n",
    "- Production Companies\n",
    "- URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vh28ViF27wKt"
   },
   "source": [
    "## Install BeautifullSoup and Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "r_852zep7kmQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.0.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Hemanth\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.0.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Hemanth\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 --quiet\n",
    "!pip install requests --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwLXw_dajF3o"
   },
   "source": [
    "## Scrape the list of top voted movies from IMDB\n",
    "- Use requests to download the page\n",
    "- Use BeautifulSoup to parse and extract information information\n",
    "- Use pandas to convert this data into a dataframe and to save it in a CSV file\n",
    "\n",
    "Let's write a function to download the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ARjAVrwKm8kw"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, re, time\n",
    "import pandas as pd\n",
    "\n",
    "def get_top50_movies_page(year):\n",
    "  main_page_url = f\"https://www.imdb.com/search/title/?title_type=feature&year={year}-01-01,{year}-12-31&sort=num_votes,desc\"\n",
    "  response = requests.get(main_page_url)\n",
    "  doc = BeautifulSoup(response.text, 'html.parser')\n",
    "  return doc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujQDnIP-oR72"
   },
   "source": [
    "`get_top50_movies_page(2021)` uses `requests` to download the page which contains the top 50 movies based on the number of votes for the year of `2021`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IQbLdExnoJAe"
   },
   "outputs": [],
   "source": [
    "sample_doc = get_top50_movies_page(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aYy8JzooIWu"
   },
   "source": [
    "Let's create an another function to prase `title`, `movie_url`, `duration` and `votes` for each movie.\n",
    "\n",
    "To get the list of all movies in the page, we can pick `div` tags with the `class`\n",
    "\n",
    "In this example the class name is `lister-item-content`\n",
    "\n",
    "![picture](https://drive.google.com/uc?id=1Iv2XlX6EaWkSWVB7Zyo8AuJWYzvUJK0j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "05UTvf9Co_sm"
   },
   "outputs": [],
   "source": [
    "def get_movie_basic_info(doc):\n",
    "  title_list, movie_url_list, duration_list, votes_list = [], [], [], []\n",
    "  base_url = 'https://www.imdb.com'\n",
    "\n",
    "  movies_list = sample_doc.find_all('div', {'class':'lister-item-content'})\n",
    "\n",
    "  for movie in movies_list:\n",
    "    title = movie.find('a').text\n",
    "    movie_url = base_url + movie.find('a')['href']\n",
    "    duration = int(movie.find('span', {'class': 'runtime'}).text.split()[0])\n",
    "    votes = int(movie.find('span', {'name': 'nv'}).text.replace(',',''))\n",
    "    title_list.append(title)\n",
    "    movie_url_list.append(movie_url)\n",
    "    duration_list.append(duration) \n",
    "    votes_list.append(votes)\n",
    "  return title_list, movie_url_list, duration_list, votes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RcA_Z6AIqtQM"
   },
   "outputs": [],
   "source": [
    "title_list, movie_url_list, duration_list, votes_list = get_movie_basic_info(sample_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUychDlUtPUU"
   },
   "source": [
    "Use the lists to craete a CSV file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lptNCESRqyJ9"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Title': title_list,\n",
    "                   'URL': movie_url_list,\n",
    "                   'DUration': duration_list,\n",
    "                   'Votes': votes_list})\n",
    "df.to_csv(\"movies_basic_detail.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qcv4PGmCtaaG"
   },
   "source": [
    "Let's write a function to get more details of the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "F7pIWlFitpsA"
   },
   "outputs": [],
   "source": [
    "def get_movie_details(movie_url):\n",
    "  d = {}\n",
    "  response = requests.get(movie_url)\n",
    "  doc = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "  d['title'] = doc.find('h1').text\n",
    "  if 'Taglines' in doc.find_all('li', {'class':'ipc-metadata-list__item'})[13].text:\n",
    "    d['tagline'] = doc.find_all('span', {'class':'ipc-metadata-list-item__list-content-item'})[1].text\n",
    "  li_tags = doc.find_all('li', {'class':'ipc-metadata-list__item'})[:33]\n",
    "\n",
    "  directors = [i.text for i in li_tags[0].find_all('li')]\n",
    "  d['no_of_directors'] = len(directors)\n",
    "  d['directors'] = \",\".join(directors)\n",
    "  writers = [i.text for i in li_tags[1].find_all('li')]\n",
    "  d['no_of_writers'] = len(writers)\n",
    "  d['writers'] = ','.join(writers)\n",
    "  d['lead_stars'] = ','.join([i.text for i in li_tags[2].find_all('li')])\n",
    "  try:\n",
    "    oscars = li_tags[8].find('a').text\n",
    "    d['oscar_wins'] = int(re.findall('Won \\d+ Oscar', oscars)[0].split()[1])\n",
    "  except:\n",
    "    d['oscar_wins'] = 0\n",
    "\n",
    "  genres =  doc.find('li', {'data-testid':'storyline-genres'}).find('ul').find_all('li')\n",
    "  d['genres'] = ','.join([i.text for i in genres])\n",
    "  \n",
    "  try:\n",
    "    awards = li_tags[8].find('li').text\n",
    "  except:\n",
    "    awards = li_tags[9].find('li').text\n",
    "\n",
    "  try:\n",
    "    d['award_nominations'] = int(re.findall('\\d+ nomination', awards)[0].split()[0])\n",
    "  except:\n",
    "    d['award_nominations'] = 0\n",
    "  try:\n",
    "    d['award_wins'] = int(re.findall('\\d+ win', awards)[0].split()[0])\n",
    "  except:\n",
    "    d['award_wins'] = 0\n",
    "\n",
    "  d['rating'] = float(doc.find('span', {'class':'AggregateRatingButton__RatingScore-sc-1ll29m0-1'}).text)\n",
    "\n",
    "  try:\n",
    "    d['metascore'] = int(doc.find_all('span', {'class':'score'})[2].text.replace(',',''))\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  countries = doc.find('div', {'data-testid':'title-details-section'}).find('ul').find_all('li')[2].find('ul').find_all('li')\n",
    "  d['county_of_origins'] = ','.join([i.text for i in countries])\n",
    "  productions  = doc.find('div', {'data-testid':'title-details-section'}).find('ul').find_all('ul')[-1].find_all('li')\n",
    "  d['production_companies'] = ','.join([i.text for i in productions])\n",
    "  d['url'] = movie_url\n",
    "\n",
    "  return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csPN7S1suV5z"
   },
   "source": [
    "Now I will give the `movie_url_list[1]` as input url to the function `get_movie_details(movie_url)`. It will return the dictionary of details for that movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SIj09UjiuHjr",
    "outputId": "f8737da6-cf0a-4ea7-8a52-50ac82e5ff8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Spider-Man: No Way Home', 'https://www.imdb.com/title/tt10872600/')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_list[1], movie_url_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uW0N_bosut88",
    "outputId": "c4d41a6c-a74e-4ca3-b888-2b174612a467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Spider-Man: No Way Home', 'tagline': 'The Multiverse Unleashed.', 'no_of_directors': 1, 'directors': 'Jon Watts', 'no_of_writers': 3, 'writers': 'Chris McKenna,Erik Sommers,Stan Lee(based on the Marvel comic book by)', 'lead_stars': 'Tom Holland,Zendaya,Benedict Cumberbatch', 'oscar_wins': 0, 'genres': 'Action,Adventure,Fantasy,Sci-Fi', 'award_nominations': 32, 'award_wins': 5, 'rating': 8.7, 'metascore': 71, 'county_of_origins': 'United States', 'production_companies': 'Columbia Pictures,Pascal Pictures,Marvel Studios', 'url': 'https://www.imdb.com/title/tt10872600/'}\n"
     ]
    }
   ],
   "source": [
    "Spider_Man_movie_data = get_movie_details(movie_url_list[1])\n",
    "print(Spider_Man_movie_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J156fk5XtaWl"
   },
   "source": [
    "## Putting all together\n",
    "- We have a function to get top 50 movies of a particular year, wll add pagination in url to get next 50 movies\n",
    "- We have a function to parse the more details of each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cKNuNA6Y7171"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, re, time\n",
    "import pandas as pd\n",
    "\n",
    "base_url = 'https://www.imdb.com'\n",
    "\n",
    "all_data = []\n",
    "def get_main_page_data(year):\n",
    "  global all_data\n",
    "  main_page_url = f\"https://www.imdb.com/search/title/?title_type=feature&year={year}-01-01,{year}-12-31&sort=num_votes,desc\"\n",
    "  l = []\n",
    "  for url in [main_page_url, main_page_url+'&start=51&ref_=adv_nxt']:\n",
    "    response = requests.get(url)\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    movies_list = doc.find_all('div', {'class':'lister-item-content'})\n",
    "    for movie in movies_list:\n",
    "      movie_url = base_url + movie.find('a')['href']\n",
    "      duration = int(movie.find('span', {'class': 'runtime'}).text.split()[0])\n",
    "      votes = int(movie.find('span', {'name': 'nv'}).text.replace(',',''))\n",
    "      \n",
    "      # get the movie details by running get_movie_data() for each movie and add it to a list\n",
    "      l.append(get_movie_data(movie_url, duration, votes, year))\n",
    "  all_data.extend(l)\n",
    "  df = pd.DataFrame(l)\n",
    "\n",
    "  # Save the top 100 voted movies details inside Resulst folder\n",
    "  df.to_csv(f'./Results/{year}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tX7FWynHkd3E"
   },
   "source": [
    "Let's write an another function to fetch the more details of the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yZnhRb3R9rr-"
   },
   "outputs": [],
   "source": [
    "def get_movie_data(movie_url, duration, votes, year):\n",
    "  d = {}\n",
    "  response = requests.get(movie_url)\n",
    "  doc = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "  d['title'] = doc.find('h1').text\n",
    "  if 'Taglines' in doc.find_all('li', {'class':'ipc-metadata-list__item'})[13].text:\n",
    "    d['tagline'] = doc.find_all('span', {'class':'ipc-metadata-list-item__list-content-item'})[1].text\n",
    "  li_tags = doc.find_all('li', {'class':'ipc-metadata-list__item'})[:33]\n",
    "\n",
    "  directors = [i.text for i in li_tags[0].find_all('li')]\n",
    "  d['no_of_directors'] = len(directors)\n",
    "  d['directors'] = \",\".join(directors)\n",
    "  writers = [i.text for i in li_tags[1].find_all('li')]\n",
    "  d['no_of_writers'] = len(writers)\n",
    "  d['writers'] = ','.join(writers)\n",
    "  d['lead_stars'] = ','.join([i.text for i in li_tags[2].find_all('li')])\n",
    "  d['released_year'] = year\n",
    "  try:\n",
    "    oscars = li_tags[8].find('a').text\n",
    "    d['oscar_wins'] = int(re.findall('Won \\d+ Oscar', oscars)[0].split()[1])\n",
    "  except:\n",
    "    d['oscar_wins'] = 0\n",
    "\n",
    "  genres =  doc.find('li', {'data-testid':'storyline-genres'}).find('ul').find_all('li')\n",
    "  d['genres'] = ','.join([i.text for i in genres])\n",
    "  \n",
    "  try:\n",
    "    awards = li_tags[8].find('li').text\n",
    "  except:\n",
    "    awards = li_tags[9].find('li').text\n",
    "\n",
    "  try:\n",
    "    d['award_nominations'] = int(re.findall('\\d+ nomination', awards)[0].split()[0])\n",
    "  except:\n",
    "    d['award_nominations'] = 0\n",
    "  try:\n",
    "    d['award_wins'] = int(re.findall('\\d+ win', awards)[0].split()[0])\n",
    "  except:\n",
    "    d['award_wins'] = 0\n",
    "\n",
    "  d['rating'] = float(doc.find('span', {'class':'AggregateRatingButton__RatingScore-sc-1ll29m0-1'}).text)\n",
    "  d['votes'] = votes\n",
    "\n",
    "  try:\n",
    "    d['metascore'] = int(doc.find_all('span', {'class':'score'})[2].text.replace(',',''))\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  d['duration'] = duration\n",
    "  countries = doc.find('div', {'data-testid':'title-details-section'}).find('ul').find_all('li')[2].find('ul').find_all('li')\n",
    "  d['county_of_origins'] = ','.join([i.text for i in countries])\n",
    "  productions  = doc.find('div', {'data-testid':'title-details-section'}).find('ul').find_all('ul')[-1].find_all('li')\n",
    "  d['production_companies'] = ','.join([i.text for i in productions])\n",
    "  d['url'] = movie_url\n",
    "\n",
    "  return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4to_n8p7vfNo"
   },
   "source": [
    "Now call a function for year 2011 to 2021 using a for loop to get the top voted 100 movies for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "vW5W5oufHCz_",
    "outputId": "10ff563f-7121-49c7-8db8-3a51a2c5888a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011 is done!\n"
     ]
    }
   ],
   "source": [
    "for year in range(2011,2022):\n",
    "    get_main_page_data(year)\n",
    "    print(f\"{year} is done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_9ZtDlFvtdk"
   },
   "source": [
    "Yearly based data for each year is stored in CSV files. Use `all_data` variable and create a master sheet which contails all years of data in a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LvPEQe_UaG9r"
   },
   "outputs": [],
   "source": [
    "df  = pd.DataFrame(all_data)\n",
    "df.to_csv(\"./Results/Merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyS-QR3vxjeH"
   },
   "source": [
    "Read the top 5 rows of `Merged.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEWM1I9jxgUm",
    "outputId": "63fd580c-a861-4e54-c07a-07bff2fd4090"
   },
   "outputs": [],
   "source": [
    "merged_data = pd.read_csv('./Results/Merged.csv')\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRTUArDZgJJ7"
   },
   "source": [
    "## Summary\n",
    "- Parsed the top voted 100 movies for each year from https://www.imdb.com\n",
    "- For each movie parsed the more important data and stored a yearly based data in CSV files inside `Results` folder\n",
    "- Created a one more CSV file which contains all years of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zhUZ4Sjyx6V"
   },
   "source": [
    "## Ideas for future work\n",
    "- Use this data for Exploratory Data Analysis"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WebScrapping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
